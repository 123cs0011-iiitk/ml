# Stock Price Insight Arena
# ğŸ“ˆ Stock Price Prediction System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)](https://flask.palletsprojects.com)
[![React](https://img.shields.io/badge/React-18+-blue.svg)](https://reactjs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-4.0+-blue.svg)](https://typescriptlang.org)
[![CSV](https://img.shields.io/badge/Data_Storage-CSV-orange.svg)](https://en.wikipedia.org/wiki/Comma-separated_values)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive full-stack web application that leverages machine learning algorithms to predict future stock prices based on historical data. The system provides real-time stock price fetching, data analysis, and interactive visualizations for informed investment decisions using CSV files for efficient data storage.

## âœ¨ Features

- **Real-time Stock Data**: Fetch live stock prices and historical data from multiple sources
- **CSV Data Storage**: Lightweight file-based storage for stock price data and historical records
- **Machine Learning Predictions**: Multiple ML algorithms including LSTM, Random Forest, and Linear Regression
- **Interactive Dashboard**: React-based frontend with TypeScript for type safety and better UX
- **Data Visualization**: Charts and graphs showing price trends and prediction accuracy
- **RESTful API**: Well-documented API endpoints for data access and predictions
- **File-based Storage**: CSV files for efficient data management and easy data portability
- **Data Processing**: Advanced preprocessing and feature engineering capabilities
- **Model Evaluation**: Comprehensive model performance metrics and backtesting

## ğŸ› ï¸ Technology Stack

### Backend (Modular Architecture)
- **Flask** - Python web framework for API development
- **Modular Design** - Organized into specialized modules (live-data, algorithms, prediction, etc.)
- **CSV Files** - Lightweight data storage for stock prices and historical records
- **Pandas** - Data manipulation and CSV file operations
- **NumPy** - Numerical computations
- **Scikit-learn** - Machine learning algorithms (Random Forest, SVM, etc.)
- **TensorFlow/Keras** - Deep learning models (LSTM, Neural Networks)
- **Matplotlib/Seaborn** - Data visualization
- **yfinance** - Real-time stock data fetching
- **Multiple API Fallbacks** - Finnhub, Alpha Vantage for reliability

### Frontend
- **React** - Frontend library for building user interfaces
- **TypeScript** - Type-safe JavaScript for better development experience
- **Axios** - HTTP client for API communication
- **Chart.js/D3.js** - Interactive charts and visualizations
- **Material-UI** - Component library for consistent design

### Data Storage Architecture

#### Master Index Files
- **`data/index_us_stocks_dynamic.csv`** - Master index for all US stocks (500+ stocks)
- **`data/index_ind_stocks_dynamic.csv`** - Master index for all Indian stocks (500+ stocks)
- These are the ONLY index files and single source of truth for stock metadata
- Automatically updated when new stocks are discovered
- Maintained in alphabetical order by symbol

#### Data Directory (Read/Write)
- **`data/latest/`** - Recent stock price data (2025+)
- **`data/past/`** - Historical stock price data (2020-2024)
- Backend actively reads and writes to this directory

#### Permanent Directory (Read-Only)
- **`permanent/`** - Manually curated historical data (2020-2024)
- Used ONLY as fallback when APIs fail
- Backend NEVER modifies this directory
- Contains 500 US stocks and 500 Indian stocks with complete historical data

#### Index File Structure
```csv
symbol,company_name,sector,market_cap,headquarters,exchange,currency
AAPL,Apple,Technology,,"Cupertino, California",NASDAQ,USD
RELIANCE,Reliance Industries,Energy,,"Mumbai, India",NSE,INR
```

### Data Storage
- **CSV Files** - Human-readable data storage format
- **JSON** - Configuration and metadata storage
- **File System** - Organized directory structure for data management

## ğŸ—ï¸ Backend Architecture

The backend has been restructured with a modular architecture for better organization and maintainability:

```
backend/
â”œâ”€â”€ main.py                 # Central coordinator and API entry point
â”œâ”€â”€ app.py                  # Legacy Flask app (backward compatibility)
â”œâ”€â”€ live-data/             # Live market data fetching
â”‚   â”œâ”€â”€ live_data_manager.py
â”‚   â””â”€â”€ live_fetcher.py    # Multi-API fallback system
â”œâ”€â”€ company-info/          # Company information management
â”‚   â””â”€â”€ company_info_manager.py  # [FUTURE] Fundamentals, metadata
â”œâ”€â”€ algorithms/            # Stock prediction algorithms
â”‚   â””â”€â”€ prediction_algorithms.py  # [FUTURE] 10+ ML algorithms
â”œâ”€â”€ prediction/           # Prediction orchestration
â”‚   â””â”€â”€ prediction_engine.py  # [FUTURE] Algorithm coordination
â”œâ”€â”€ shared/               # Shared utilities and common code
â”‚   â””â”€â”€ utilities.py      # Configuration, logging, validation
â””â”€â”€ requirements.txt
```

### Module Responsibilities

- **live-data/**: Real-time stock price fetching with multiple API fallbacks
- **company-info/**: Company fundamentals, metadata, and financial data
- **algorithms/**: 10+ prediction algorithms (Random Forest, LSTM, ARIMA, etc.)
- **prediction/**: Algorithm selection, data preprocessing, and result formatting
- **shared/**: Common utilities, configuration, and data structures

## ğŸ“‹ Prerequisites

Before running this project, make sure you have the following installed:

- Python 3.8 or higher
- Node.js 16.0 or higher
- Git

## ğŸš€ Installation and Setup

### 1. Clone the Repository

```bash
git clone https://github.com/123cs0011-iiitk/ml.git
cd ml
```

### 2. Backend Setup

#### Create Virtual Environment
```bash
cd backend
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

#### Install Dependencies
```bash
pip install -r requirements.txt
```

#### Environment Configuration
Create a `.env` file in the backend directory:
```text
FLASK_APP=app.py
FLASK_ENV=development
SECRET_KEY=your-secret-key-here
STOCK_API_KEY=your-stock-api-key
DATA_DIRECTORY=../data/stock_data
```

#### Initialize Data Directory Structure
```bash
python -c "from app.utils.data_manager import initialize_data_structure; initialize_data_structure()"
```

### 3. Frontend Setup

```bash
cd frontend
npm install
npm run dev
# or, to build for production:
# npm run build
```


#### Environment Configuration
Create a `.env` file in the frontend directory:
```text
REACT_APP_API_BASE_URL=http://localhost:5000/api
REACT_APP_ENVIRONMENT=development
```

## ğŸƒâ€â™‚ï¸ Running the Application

### Start Backend Server
```bash
cd backend
flask run
# Server will start on http://localhost:5000
```

### Start Frontend Development Server
```bash
cd frontend
npm start
# Application will open on http://localhost:3000
```

## ğŸ“ Project Structure

```
stock-price-prediction/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ stock_data.py
â”‚   â”‚   â”‚   â””â”€â”€ prediction.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.py
â”‚   â”‚   â”‚   â””â”€â”€ stock_routes.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ data_fetcher.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_models.py
â”‚   â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ csv_manager.py
â”‚   â”‚       â”œâ”€â”€ data_processor.py
â”‚   â”‚       â””â”€â”€ validators.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StockChart.tsx
â”‚   â”‚   â”‚   â””â”€â”€ PredictionPanel.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ stock.ts
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ formatters.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ index.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ stock_data/
â”‚   â”‚   â”œâ”€â”€ daily/
â”‚   â”‚   â”‚   â”œâ”€â”€ AAPL.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ GOOGL.csv
â”‚   â”‚   â”‚   â””â”€â”€ MSFT.csv
â”‚   â”‚   â”œâ”€â”€ predictions/
â”‚   â”‚   â”‚   â””â”€â”€ prediction_results.csv
â”‚   â”‚   â””â”€â”€ metadata/
â”‚   â”‚       â””â”€â”€ stock_info.json
â”‚   â””â”€â”€ sample_data/
â”‚
â”œâ”€â”€ ml_models/
â”‚   â”œâ”€â”€ trained_models/
â”‚   â”œâ”€â”€ lstm_model.py
â”‚   â”œâ”€â”€ random_forest_model.py
â”‚   â””â”€â”€ model_evaluator.py
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ api_documentation.md
â”‚
â””â”€â”€ README.md
```

## ğŸ“Š Machine Learning Models

### Supported Algorithms

1. **LSTM (Long Short-Term Memory)**
   - Best for sequential time series prediction
   - Captures long-term dependencies in stock price movements

2. **Random Forest**
   - Ensemble method reducing overfitting
   - Good for handling non-linear relationships

3. **Linear Regression**
   - Baseline model for comparison
   - Fast training and prediction

### Model Training
```bash
cd backend
python -c "from app.services.ml_models import train_models; train_models()"
```

## ğŸ“„ Data Storage Format

### Stock Price CSV Structure
```csv
Date,Open,High,Low,Close,Volume
2024-01-01,150.00,155.50,149.75,154.25,1000000
2024-01-02,154.25,158.00,153.50,157.75,1200000
2024-01-03,157.75,159.25,156.00,158.50,950000
```

### Prediction Results CSV Structure
```csv
Symbol,Date,Actual_Price,Predicted_Price,Model,Accuracy
AAPL,2024-01-04,160.00,159.25,LSTM,0.995
AAPL,2024-01-04,160.00,158.75,Random_Forest,0.992
AAPL,2024-01-04,160.00,161.50,Linear_Regression,0.990
```

## ğŸ”Œ API Endpoints

### Stock Data Endpoints
```
GET /api/stocks                 # Get all tracked stocks
GET /api/stocks/{symbol}        # Get specific stock data from CSV
POST /api/stocks                # Add new stock to tracking
DELETE /api/stocks/{symbol}     # Remove stock CSV file
```

### Data Management Endpoints
```
GET /api/data/historical/{symbol}  # Read historical data from CSV
POST /api/data/update              # Update CSV files with new data
GET /api/data/stats                # Get CSV file statistics
POST /api/data/export              # Export data in various formats
```

### Prediction Endpoints
```
GET /api/predict/{symbol}       # Get price prediction for stock
POST /api/predict/batch         # Batch prediction for multiple stocks
GET /api/models/performance     # Get model performance metrics
```

## ğŸ’» Usage

### 1. Adding Stocks for Tracking
Navigate to the dashboard and use the stock search feature to add stocks. The system will create CSV files for each stock automatically.

### 2. Data Management
- **Automatic CSV Creation**: New stock CSV files are created when adding stocks to tracking
- **Data Updates**: Historical data is appended to existing CSV files
- **File Organization**: Each stock has its own CSV file in the `data/stock_data/daily/` directory

### 3. Viewing Predictions
Select a stock from your watchlist to view:
- Historical price charts loaded from CSV files
- ML model predictions
- Accuracy metrics
- Confidence intervals

## ğŸ”§ Configuration

### CSV File Management
```python
# Example CSV operations
import pandas as pd

# Load stock data
df = pd.read_csv('data/stock_data/daily/AAPL.csv')

# Append new data
new_data = pd.DataFrame({
    'Date': ['2024-01-04'],
    'Open': [158.50],
    'High': [162.00],
    'Low': [157.25],
    'Close': [161.75],
    'Volume': [1100000]
})
df = pd.concat([df, new_data], ignore_index=True)
df.to_csv('data/stock_data/daily/AAPL.csv', index=False)
```

### Data Directory Structure
The system automatically creates and maintains the following structure:
```
data/
â”œâ”€â”€ stock_data/
â”‚   â”œâ”€â”€ daily/          # Daily stock price CSV files
â”‚   â”œâ”€â”€ predictions/    # Model prediction results
â”‚   â””â”€â”€ metadata/       # Stock information and configurations
```

## ğŸ§ª Testing

### Backend Tests
```bash
cd backend
python -m pytest tests/
```

### Frontend Tests
```bash
cd frontend
npm test
```

### Data Integrity Tests
```bash
cd backend
python -c "from app.utils.csv_manager import validate_csv_files; validate_csv_files()"
```

## ğŸš§ Troubleshooting

### Common Issues

#### CSV File Corruption
- Check file permissions in data directory
- Validate CSV format using pandas
- Restore from backup if available

#### Missing Data Files
- Run data initialization: `python -c "from app.utils.data_manager import initialize_data_structure; initialize_data_structure()"`
- Check if stock symbol CSV files exist

#### API Key Issues
- Ensure stock API key is valid and has sufficient quota
- Check API rate limits

#### Model Training Fails
- Verify sufficient historical data in CSV files
- Check CSV file format and data quality

#### Frontend Build Errors
- Clear npm cache: `npm cache clean --force`
- Delete node_modules and reinstall: `rm -rf node_modules && npm install`

## ğŸ”® Future Enhancements

- Real-time WebSocket connections for live price updates
- Data compression for large CSV files
- Advanced technical indicators integration
- Sentiment analysis using news data
- Portfolio optimization features
- Mobile app development
- Advanced charting capabilities
- User authentication and personalized dashboards
- Database migration option for scaling
- Cloud storage integration for CSV files

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint and Prettier for TypeScript/React code
- Write tests for new features
- Update documentation for API changes
- Ensure CSV file integrity in data operations

## âš ï¸ Known Limitations

- CSV files may become large with extensive historical data
- No built-in data backup mechanism (manual backup recommended)
- Concurrent access to CSV files may cause data conflicts
- Stock market predictions are inherently uncertain and should not be used as sole investment advice
- API rate limits may affect real-time data fetching
- Model performance varies significantly across different market conditions

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

For support and questions:
- Create an issue on GitHub
- Contact the development team
- Check the documentation in the `docs/` directory

## ğŸ™ Acknowledgments

- Stock data provided by various financial APIs
- Machine learning libraries: scikit-learn, TensorFlow
- Frontend libraries: React, TypeScript community
- Data management: Pandas community for CSV operations

---

**Disclaimer**: This application is for educational and research purposes only. Stock market investments carry risk, and past performance does not guarantee future results. Always consult with financial advisors before making investment decisions.

